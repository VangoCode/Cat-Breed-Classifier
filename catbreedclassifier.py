# -*- coding: utf-8 -*-
"""CatBreedClassifier_Improved.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QA1zIYULhSoR4-8zlf7PItC7KWooSSC_

# Convolutional Neural Network

## Unzip Data
"""

!unzip cat_breed_dataset.zip

"""## Importing Necessary Libraries"""

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator

"""Ensure Tensorflow is installed"""

print(tf.__version__)

"""## Data Preprocessing"""

# to avoid overfitting, perform image augmentation:

# training set
train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        rotation_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

training_set = train_datagen.flow_from_directory(
        'training_set/',
        target_size=(128, 128),
        batch_size=32,
        class_mode='categorical')

# test set
test_datagen = ImageDataGenerator(rescale=1./255)
test_set = test_datagen.flow_from_directory(
        'test_set/',
        target_size=(128, 128),
        batch_size=32,
        class_mode='categorical')

print(training_set.class_indices)

"""## Building CNN"""

# Initialize a sequential model
cnn = tf.keras.models.Sequential()

"""#### Archetype: Simple CNN"""

# First convolutional layer
cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=[128, 128, 3]))
# Pool the CNN
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
# Second Convolutional Layer
cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu'))
# Pool the CNN
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
# Third Convolutional Layer
cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu'))
# Pool the CNN
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
#Fourth Convolution Layer
cnn.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu'))
# Pool the CNN
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))
# Regularizing to reduce overfitting
cnn.add(tf.keras.layers.Dense(64, kernel_regularizer='l2'))
# Flattening Layer
cnn.add(tf.keras.layers.Flatten())
# Full Connection Layers
cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))
# Dropout b/w layers to reduce overfitting
cnn.add(tf.keras.layers.Dropout(0.5))
cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))
# Output Layer
cnn.add(tf.keras.layers.Dense(units=7, activation='softmax'))  # multiunit classification

"""## Training CNN"""

# Compile CNN
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

from PIL import Image, ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
# Train w/ Training Set, Evaluate W/ Test Set
history = cnn.fit(x=training_set, validation_data=test_set, epochs=30)

"""# Plotting Accuracy & Loss"""

import matplotlib.pyplot as plt

acc=history.history['accuracy']
val_acc=history.history['val_accuracy']
loss=history.history['loss']
val_loss=history.history['val_loss']

epochs=range(len(acc))

fig = plt.figure(figsize=(14,7))
plt.plot(epochs, acc, 'r', label="Training Accuracy")
plt.plot(epochs, val_acc, 'b', label="Validation Accuracy")
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc='lower right')
plt.show()

fig2 = plt.figure(figsize=(14,7))
plt.plot(epochs, loss, 'r', label="Training Loss")
plt.plot(epochs, val_loss, 'b', label="Validation Loss")
plt.legend(loc='upper right')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and validation loss')

cnn.save("cat_breed_classifier_7Classes_63-acc.h5")

from google.colab import files
files.download('cat_breed_classifier_7Classes_63-acc.h5')

"""## Making a Prediction"""

import numpy as np
from keras.preprocessing.image import image
test_image = image.load_img('single_prediction/siamese.jpg', target_size=(128, 128))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis=0) # expand to batch
result = cnn.predict(test_image/255.0)
labels = np.argmax(result, axis=-1)    
# print(labels)
# print(result[0])
print(list(training_set.class_indices)[int(labels)])

print(prediction)

model = tf.keras.models.load_model('cat_breed_classifier_7Classes_63-acc.h5')

import numpy as np
from keras.preprocessing.image import image
test_image = image.load_img('single_prediction/persian.jpg', target_size=(128, 128))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis=0) # expand to batch
result = model.predict(test_image/255.0)
labels = np.argmax(result, axis=-1)    
print(training_set.class_indices)
print(labels)
print(result[0])
print(list(training_set.class_indices)[int(labels)])